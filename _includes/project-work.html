<section class="thirteen columns">
    <h1>Selected Academic Projects</h1>
    <article>
        <header>
            <h1>On Switch-based Controller Hand-offs in Software Defined Wireless Mesh Networks (2016)</h1>
        </header>
	<p align="justify">We use Expected Transmission Time (ETT) as the metric for controller hand-off inOpenFlow WMNs. ETT reflects various physical-layer characteristics, such as link traffic and end-to-end bandwidth. The experimental results showed that ETT is a better metric compared to RTT and ETX in a dynamic network with variable load across the links. ETT-based hand-off is able to respond to the excessive load in the link and make suitable hand-off decisons, whereas RTT and ETX fails in accomplishing the same with lower hand-off delay and packet dropouts.<br>
Paper (submitted) : <a target="_blank" href="https://drive.google.com/open?id=0B7qfuVtugGPONWJrYnUtREVuQk0">View here</a>
	</p>
    </article>
    <article>
        <header>
            <h1>Software Defined MICRONet (2016)</h1>
        </header>
	<p align="justify">Software Defined MICRONet architecture provides intelligent communication among physical boat clusters in the sea. This will solve the technology challenges faced by the fishermen community in India today, specifically by providing software defined Intelligent and adaptable communication and connectivity while they are out at sea. A scaled down model of Software Defined MICRONet environment was emulated in a testbed.<br>
Final Report : <a target="_blank" href="https://drive.google.com/open?id=0B7qfuVtugGPOOF9uVFRlMVRFbmc">View here</a><br>
Repository : <a target="_blank" href="https://github.com/amalrkrishna/sd-micronet">Software Defined MICRONet (2016) <i class="fa fa-external-link"></i></a>
	</p>
    </article>
    <article>
        <header>
            <h1>Navigation in a Virtual Environment using IMU MPU-6050 (2015)</h1>
        </header>
<p align="justify">Head Mounted Display(HMD) is one of the revolutionary Virtual Reality(VR) inventions of all times. But how do you move around in a Virtual Environment?. For a true VR experience you need to move around freely and naturally. Imagine a game where the user can freely roam around their backyard or walk on a frictionless surface and navigate in a virtual environment rather than sitting idle in a chair. Developing a low-cost system for such a VR experience which can be implemented onto a HMD, is always a challenge. In this project we have done a hardware implementation to navigate in a virtual environment using a low-cost Inertial Measurement Unit(IMU).<br>
Repository : <a target="_blank" href="https://github.com/amalrkrishna/virtualnav-mpu6050">Navigation in a Virtual Environment using IMU MPU-6050 (2015) <i class="fa fa-external-link"></i></a>
	</p>
    </article>
    <article>
    <header>
            <h1>32 bit RISC Microprocessor in VHDL language and implemented on Altera FPGA (2014)</h1>
        </header>
<p align="justify">Developed a 32 bit RISC Microprocessor in VHDL language and implemented on Altera FPGA. The Test bench module is executed in the model-sim software and the LCD module is implemented on the FPGA to display the Register value, Memory value and the Program counter.<br>
Repository : <a target="_blank" href="https://github.com/amalrkrishna/32bitrisc-vhdl">32 bit RISC Microprocessor in VHDL language and implemented on Altera FPGA (2014) <i class="fa fa-external-link"></i></a>
	</p>
    </article>
    <article>
    <header>
            <h1>2D convolution using Xlinix of a 128*128 window and by using a 3*3 convolution matrix (2014)</h1>
        </header>
<p align="justify">For each input pixel window, the values in that window are multiplied by the convolution mask. Next, those results are added together and divided by the number of pixels in the window. This value is the output for the origin pixel of the output image for that position. The input pixel window is always the same size as the convolution mask. The output pixel is rounded to the nearest integer. The results for this algorithm carried over an entire input image will result in an output image with reduced salt-and-pepper noise. This flexibility allows for many powerful uses.
	</p>
    </article>
</section>
